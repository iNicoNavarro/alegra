{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e867d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import logging\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from utils.connections.sql_server_connector import SQLServerConnector\n",
    "from utils.trackers import setup_logging\n",
    "from src.innova.config.config import etl_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f72710",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logging(etl_config[\"paths\"][\"logs_path\"])\n",
    "logger.info(\"▶ populate_dim_date_2023 iniciado\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"populate_dim_date_2023\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324c6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DWH_SCHEMA: str = \"dwh_innova\"                 \n",
    "TABLE_NAME: str = f\"{DWH_SCHEMA}.dim_date\"\n",
    "DATE_START: str = dt.date(2023, 1, 1)\n",
    "DATE_END: str = dt.date(2023, 12, 31)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fafc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = (DATE_END - DATE_START).days + 1\n",
    "df_dates = (\n",
    "    spark\n",
    "    .range(ndays)\n",
    "    .withColumn(\"full_date\", F.expr(f\"date_add('{DATE_START}', cast(id as int))\"))\n",
    "    .withColumn(\"date_id\", F.date_format(\"full_date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"day_of_month\", F.dayofmonth(\"full_date\").cast(\"tinyint\"))\n",
    "    .withColumn(\"month\", F.month(\"full_date\").cast(\"tinyint\"))\n",
    "    .withColumn(\"month_name\", F.date_format(\"full_date\", \"MMMM\"))\n",
    "    .withColumn(\"quarter\", F.quarter(\"full_date\").cast(\"tinyint\"))\n",
    "    .withColumn(\"year\", F.year(\"full_date\").cast(\"smallint\"))\n",
    "    .withColumn(\"week_of_year\", F.weekofyear(\"full_date\").cast(\"tinyint\"))\n",
    "    .withColumn(\n",
    "        \"is_weekend\",\n",
    "        (F.dayofweek(\"full_date\").isin([1, 7])).cast(\"boolean\")\n",
    "    )\n",
    "    .select(\n",
    "        \"date_id\", \"full_date\", \"day_of_month\", \"month\",\n",
    "        \"month_name\", \"quarter\", \"year\", \"week_of_year\", \"is_weekend\"\n",
    "    )\n",
    ")\n",
    "\n",
    "logger.info(f\"Generadas {df_dates.count():,} filas para 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7712ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----+----------+-------+----+------------+----------+\n",
      "| date_id| full_date|day_of_month|month|month_name|quarter|year|week_of_year|is_weekend|\n",
      "+--------+----------+------------+-----+----------+-------+----+------------+----------+\n",
      "|20230101|2023-01-01|           1|    1|   January|      1|2023|          52|      true|\n",
      "|20230102|2023-01-02|           2|    1|   January|      1|2023|           1|     false|\n",
      "|20230103|2023-01-03|           3|    1|   January|      1|2023|           1|     false|\n",
      "|20230104|2023-01-04|           4|    1|   January|      1|2023|           1|     false|\n",
      "|20230105|2023-01-05|           5|    1|   January|      1|2023|           1|     false|\n",
      "|20230106|2023-01-06|           6|    1|   January|      1|2023|           1|     false|\n",
      "|20230107|2023-01-07|           7|    1|   January|      1|2023|           1|      true|\n",
      "|20230108|2023-01-08|           8|    1|   January|      1|2023|           1|      true|\n",
      "|20230109|2023-01-09|           9|    1|   January|      1|2023|           2|     false|\n",
      "|20230110|2023-01-10|          10|    1|   January|      1|2023|           2|     false|\n",
      "|20230111|2023-01-11|          11|    1|   January|      1|2023|           2|     false|\n",
      "|20230112|2023-01-12|          12|    1|   January|      1|2023|           2|     false|\n",
      "|20230113|2023-01-13|          13|    1|   January|      1|2023|           2|     false|\n",
      "|20230114|2023-01-14|          14|    1|   January|      1|2023|           2|      true|\n",
      "|20230115|2023-01-15|          15|    1|   January|      1|2023|           2|      true|\n",
      "|20230116|2023-01-16|          16|    1|   January|      1|2023|           3|     false|\n",
      "|20230117|2023-01-17|          17|    1|   January|      1|2023|           3|     false|\n",
      "|20230118|2023-01-18|          18|    1|   January|      1|2023|           3|     false|\n",
      "|20230119|2023-01-19|          19|    1|   January|      1|2023|           3|     false|\n",
      "|20230120|2023-01-20|          20|    1|   January|      1|2023|           3|     false|\n",
      "+--------+----------+------------+-----+----------+-------+----+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd41c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with SQLServerConnector(spark, logger=logger) as sql_conn:\n",
    "    # sql_conn.execute_sql(f\"TRUNCATE TABLE {TABLE_NAME}\")\n",
    "    sql_conn.write_dataframe(\n",
    "        df_dates,\n",
    "        table=TABLE_NAME,\n",
    "        mode=\"append\",\n",
    "        options={\"batchsize\": 1000}\n",
    "    )\n",
    "\n",
    "logger.info(\"✅ dim_date 2023 cargada\")\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
